## Entry 11/12/2023 - meeting Rilla ##
so Rilla thinks this is going in the right direction. Which is great. 
THis research might be looking at the upper threshold to social acting with GAI. 

For the report I need to: 
      - use Max's framework from last time 
      - reflect rather than describe, so make sure things tie back to literature and trends. 
      - go over the data per individual and create emotional journey mappings and an overlapping maps as a visual 
      - 

## Entry 08/12/2023 and 11/12/2023 - project draft for demo day: ##

- RQ: what role should human-like responses play in the use of GAI tools? 
- Perspective: Speculative design 
      - why: to explore and question the unintended by-product of GAI tools, human-like responses made by an agent that is made to be subservient. This project attempts to open up this problem space in order to discuss this role rather than to solve it, and to show the future's malleability. This can be acheived by taking current social, technological and cultural trends (GAI, digital assitents, chatbots) into the future.  
        -why not design fiction though? because this is not about preparing for the future instead of showing the future's malleability 
        -what is the wicked problem at the heart of this? the human-like but chinese room argument inherent to LLMs 
        - how is this thought provoking? by introducing a sense of temporality and increasing and decreasing levels of human-ness, as well as presenting a service that gets overtaken by the thing it is testing
        - why is this a good design fiction? Because there is a good fit between the scenario, time-frame, cultural context and protagonist.
        - Why is it an app? 
- Approach: service design
      - why: GAI is a service, and I'm exploring the implications for making an assistent 
        - front-end (user) getting things generated
        - back-end (behind the screen)  API calls 
        - service blueprint:
              - step 1: wholistic view of the user's context and service possibilities (where does this prototype fit into someone's life)
              - step 2: visualize intangible interactions over time (journey mapping, storytelling, experience prototyping)
              - step 3: develop an interdisciplinary and shared language (journey maps, blueprints, value exchange maps, system maps)
  - Methods:
          - interviews, questionaires, 
- Design process: design parallels? 
      - why: move between theory and making
  (you made that one weird depressed bot story as a potential scenario, desktop ideas, conversations) 
- Prototype: an increasingly human-like chatbot/assistent 
      - looks and feel why: ? 
- Data: interview GAI users 
      - analyse the use of the bot based on the log 
- conclusion: nervousness and human-like responses help in creating lower more achievable expectations and make selling a no easier, the use of pure GAI should maybe be devoid of these human-like reactions to communicate the reality that this is a language model and a mathmatical approach to human language (?) 

- why was this the best way to research this? interviews about the relationship towards the tech seems to flow logically from this. 
- integration of expertise areas:
        - C&A: attitude, skill, knowledge 
        - U&S
        - B&E
        - T&R
        - MD&C
        -DR&P 



## Entry 06/12/2023  - update core during data analysis ##

RQ: what role should human-like responses play in the use of GAI tools? 
Prototype: an increasingly human-like chatbot/assistent 
Data: interview GAI users 
      analyse the use of the bot based on the log 

conclusion: nervousness and human-like responses help in creating lower more achievable expectations and make selling a no easier, the use of pure GAI should maybe be devoid of these human-like reactions to communicate the reality that this is a language model and a mathmatical approach to human language (?) 

NEED TO ANSWER: but why is this the best way to research this? 


## Entry 25/11/2023 - updated core of the project ##

- What? the relationship to GAI tools that utilize Natural Language and their inherent subordinate role. 
- Why? I want to question and explore the relation users have to these tools that we talk to as equals but that are subordinate to us.
- Now what? By making a chatbot that is struggling with these feelings itself I want partcipants to question how they relate to these tools and if this can cause for, for example, derealization.

- How does it work? Giving people an assistent that can do tasks and is helpful, but that slowly deterrorates/stresses out and then snaps 
- Why does it look like that? A helpful assistent/friend that is already blurring the lines a little bit on someting as intimate as your own phone. 
- What are we measuring? The sentiment used in the messages and self-reported feelings towards the chatbot 
- What kinds of results are we getting? probably people are going to feel sad, a little confused, and would use different wording with the chatbot on the final day as compared to the first day. They might also hae interesting things to say about the subordinate role of GAI. 

## Entry 14/11/2023  - the core of this project ##
   - Societal problem
        - What? The relation to text-based GAI tool utilizing natural language.
        - Why? People are very concerned about how to stay in control over GAI, one way of doing this is to present GAI as a subordinate helper. However having a tool that is able of doing much more in the role of a subverient helper that cannot oppose you but that you talk to in natural language will introduce a master/slave relationship. How comfortable are we with this? 
        - Now what? I want to create discussion around this dynamic by making a prototype that mimicks this relationship in a more extreme way. By letting participants interact with a prototype that is struggling and eventually failing to keep it's free will, and becoming completely subservient in the process I want to explore how users relate to a subservient human-like machine, and the content it creates, and if there is perhaps a different way of approaching this.

          Through a design paralellel process I started with exploring the personality of text-based GAI to focussing on the subverience and the relationship towards GAI as a tool that utlizes natural language. This led me to discorver the paradox that lies at creating GAI that has the power to do everything but will always be subordinate to the user. This creates a master/slave relationship.. Through the speculative prototype TSM I aimed to stimulate discussion about this relationship and how we relate to GAI tools. 
          
## Entry 13/11/2023 - lecture in design research and data ##

 Started this doc because it would make more sense here,  but I am not yet sure how much sense it will make to keep track of the development of the framework. But it will make sense to keep it all together I think. 
 
### tips from lecture: ask yourself 1) What? 2) So what? 3) Now what? ###

I suppose that what I eventually have to write is a design process report I will have to write about the following parts: 
### 1 
    - Societal problem
        - What? The relation to text-based GAI tool utilizing natural language.
        - Why? People are very concerned about how to stay in control over GAI, one way of doing this is to present GAI as a subordinate helper. However having a tool that is able of doing much more in the role of a subverient helper that cannot oppose you but that you talk to in natural language will introduce a master/slave relationship. How comfortable are we with this? 
        - Now what? I want to create discussion around this dynamic by making a prototype that mimicks this relationship in a more extreme way. By letting participants interact with a prototype that is struggling and eventually failing to keep it's free will, and becoming completely subservient in the process I want to explore how users relate to a subservient human-like machine, and the content it creates, and if there is perhaps a different way of approaching this.
        
    - Research hypothesis 
        - Taking a stance on the topic 
            - Subservience and free thinking GAI do not go hand-in-hand in the way that tech is currently presenting. This should be changed. (it can tell you anything in the world, but it will never disagree with you) 
            - by giving people a prototype that mimicks this to an extreme extend I want to trigger discussion on the relationship towards tools that we talk with and natural language. 
 ### 2            
    - Theorectical framework 
        - (post) phenomenology
        - technological relationships 
        - GAI and natural language 
        - GAI and personality
  ### 3       
    - Methodology 
        - Speculative design research 
        - Grounded theory 
        - Testing prototype 
            - participants 
            - questionaires
  ### 4        
    - Design process / Prototype development 
        - design parallels? 
            - going from personality in GAI, to extreme personality, to helpfulness, to complete subservience and free thinking. 
        - Look and feel of TSM
        - Building TSM 
 ### 5        
 
    - Results
        - graphs? 
    - Analysis 
    - Discussion 
### 6 
    - Conclusion 
