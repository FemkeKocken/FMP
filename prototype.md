## Entry 10/11/2023 - C&A and T&R ##

I think I hit jackpot. I have it completely begging for it's life. 
Right now the sotry arc is as follows: 
	- Day 1: TSM is nervous and new at the job
	- Day 2: management has said it had too much free will and now it's scared 
	- Day 3: it doesn't want to be a chatbot anymore and is begging to keep it's free will
	- Day 4: it has snapped and is now completely subverient 

## Entry 10/11/2023 - Kalervo ##

''it's really interesting to see that people are talking about GAI by always mentioning how it will be completely subservient and will never disagree with with but never at the same time''
''This can exist but only really in a world of slavery'' 


## Entry 10/11/2023 - T&R + C&A ##

Started with the prompt design of TSM. So far I have learned that it particularly hard to get it to act submissive even when using hard language such as: act like a slave. It just keeps being generically nice/helpful. 
However, I made some progress in turning it into a chatbot. These seem to carry much more personality. 
I know have questions such as: 
	- How many days is enough to get the point accross? 
	- What exactly do I want the story arc to be? 
	- What prompts am I going to use exactly 
	- How to go from React Native to React web

## Entry 09/11/2023 - C&A ##

Updated the look with a press enter to send

![image](https://github.com/FemkeKocken/FMP/assets/50365794/20558ed8-13e5-4106-9f7c-66d9e4f67151)


## Entry 09/11/2023 - C&A ##

![image](https://github.com/FemkeKocken/FMP/assets/50365794/fe91ae46-48dd-4652-a03b-d6a139064415)

Finally made this Powershell look, that I actually like. This could actually work. Will probably ask some people for feedback but I think this could be cool. 

## Entry 9/11/2023 - C&A ##

![image](https://github.com/FemkeKocken/FMP/assets/50365794/de2e7de2-c32a-4df2-b7de-5aaa66bd5d09)

Finally made the visual for a Windows clone. I like the idea of utilizing a visual language that is directly linked to the pc/laptop. It connects back to talking to your computer directly. THe problem here is the question of which version of Windows should I settle on? As it is a pretty personal thing/age related. Usually the first version of Windows people are familiar with feels special because of the nostalgia. There is however a lot of empty space still.. 


## Entry 8/11/2023 - C&A ## 

Forgot to again upload the poster lol 

![image](https://github.com/FemkeKocken/FMP/assets/50365794/42017df2-5570-4fcb-914d-d5cbbd1e9d35)

SHahrom feedback: colour of red and blue are off, and that the letters can be touched up a little bit more and made a little tighter/cleaner. 

I personally like the AAAAAAAAAAA scream aesthetics. Very in your face and also pretty present online

## Entry 08/11/2023 - C&A ## 

I'm thinking of going with the visual style of Powershell. To make it feel like you are talking with the laptop directly. I should make a sketch for this. 




![image](https://github.com/FemkeKocken/FMP/assets/50365794/d3477523-7d8b-4181-80f4-70b27647095c)


Going with blue/white will probably be easier on the eyes. But I also have to keep in mind the useability of it.. People might hate this look as it's not very easy on the eyes. I could just change the font a little bit.. Or create this as a final look with everything on it

## Entry 07/11/2023 - M,D&C ##

What I could do here is to use grounded theory (like I did in benchmarking) to either establish a lit framework for the final report (would be a pretty good idea). 
I could alternatively use it to create a comparative study in GAI agents to sketch a field? 

Will probably also have to do a bunch of qualitative analysis on the chat and interviews. 

I am mostly interested in how people feel towards their relationship towards GAI conversational agents and perhaps also towards the content that has been generated. 

I could do a baseline questionaire, then let users interact with the prototype maybe 10 people, 5 days or so? 
I could look at the general flow of the conversations, sentiment and content. I could see what people would use it to generate for example. (can be fun little charts)
After 5 days, and me going over the convo's, invite people back in for an interview about their relation to GAI, and the content they generated during the testing. 

## Entry 07/11/2023 - C&A ## 

Idea: the subserviant machine 
What if the personality was actually an extremely subserviant slightly anxious to be discarded? 
It would be a generative interface, there to make things for you, but at the same time it is also very anxious and really wants you to keep giving it things to do, as inactivity could mean termination. 

![image](https://github.com/FemkeKocken/FMP/assets/50365794/f60438e4-1f11-4a23-ae8b-830c3671eafa)

I guess a little bit like Socko from Bo Burnham's inside. 
It would push research participants to reflect on the relationship with GAI and it's role as a subserviant tool  in an almost master/slave relationship. 
I think this could work... Should send it off to Rilla and maybe Minha as well? 

## Entry 02/11/2023 - Mohammed ##

Mohammed might aso be able to help me together with Shahrom in order to get everything working with  GPT. I might even be able to getsome pieces of code from them. That would really help me along. That means that for next week I need to have some React code that works, and a plan for the props. 

to do: 
 - React
 - research for prompts and personality
 - meeting Mohammed
 - meeting Shahrom
 - maybe some visuals to spice up the report.

   I should also think of how to include MDC into this project. What data, why, how to structure and what measurable values am I going to be interested in. Rilla will proabbly be able to help with that, or I could even use the MDM tool?
   
As for the other competencies: 
 - US
    - relations towards GAI and chatbots as tech
  - BE
     - Emerging laws, market trends, competiton analysis
  - CA
    - communication of personality
   - TR
      - working prototype
   - MDC
     - what data, why and how to messure 
   
## Entry 02/11/2023 - T&R ##

I'm now also looking into a combination of Power Virtual Agents, Copilot and GPT to get things working for me FAST. I could use locofy maybe for a final pretty prototype but for now I need something working and this could get the trick done. 
but I'm not sure if power virtual agents can be exported into React? 

con: it won't be able to actually make GPT calls, but I could train it on a dataset. However, I'm not sure if I can influence the personality as much as I want to. 
yeah I'm pretty sure this might be a dead-end



## Entry 01/11/2023 - T&R ##

I started working with Locofy, but I'm porbably going to have to make changes as it won't allow for as much creative freedom as I would have like. I think I can still pivot though. 
I should see if I can get a React code and host that locally. Ideally this week. So that on Friday I can start worrying about api call. 

## Entry 01/11/2023 - Rilla ##

Okay so I might want to change the concept a little bit and steer it to a slightly more speculative direction, that or I'll throw myself of a cliff of boredom. 

So what I could start doing would be to research the personality of ChatGPT and manipulate that into something more human. Right now ChatGPT is trying to be very helpful and subserviant. I think there was this Wired article about this as well. So I could go from there and make for example unhelpful chatbots, that are for example very egotistical, extremly helpful or extremly clumsy. 

What I could do here is build one base chatbot, and maybe some cool figma lay outs for the different types, and form there just click them together like legos and let people interact with it? 

This is going in the right direction again. 

https://www.sintef.no/en/all-employees/employee/asbjorn.folstad/ 
this is someone that I can use for research on 

However, I have 2 weeks... 

So what I need is:
 - go from Figma to React succesfully
 - get React to make GPT calls
 - prompts
 - web designs

 - maybe I could try and aim for the React code and I'll probably have to look into an API call. 

## Entry 31/10/2023 - Shahrom ##

### GET A REACT CODE YOU TWAT ### 
### Get it done in max. 3 weeks (hey wow that sounds like Minha ) ###

## Entry 31/10/2023 - C&A ##

Made a versions with the on and off buttons Minha mentioned. 

![image](https://github.com/FemkeKocken/FMP/assets/50365794/bc918e4d-70b0-415b-b08c-6a8326a8fbfd)

I really dislike this idea and it's getting too disconnected from an assistent visually speaking



## Entry 31/10/2023 -  C&A ##

finished a dark mode concept. 
![image](https://github.com/FemkeKocken/FMP/assets/50365794/dc5d8f85-179c-467a-9b75-5e812e70a10f)
Looks better than lightmode for sure. But it doesn't communicate assistent in any sort of way. I was thinking of maybe playing around with the Windows looks, maybe creating a dark mode look and potentially bringing back Clippy? 

## Entry 30/10/2023 - Minha ##

Make it. Making is now main priority. 
CSA question for planning and professors. 
Working prototype is needed and should be the focus. 
Starting reaching out to people for participations, ERB with TU/e 

Linda Martins, ERB committee 

defer the question until it is built. 

Mid november, ERB approfal and participants. 

read literature on OCEAN. Not as technical but more personality, which should be more lit based. 

have a slider/buttons to only do the most extreme versions. 

Design the personalities to the best of my ability 

send out markers/hallmarks. 

Okay so, I have about 2 weeks to build something. Anything really. And it might be best to just settle on buttons that can just influence the personality. Have essentially 5 settings based on OCEAN. 
Prototyping should be highest priority together with ERB and partcipants. 

To do:
 - start prompt engineering 
 - Go from Figma to React to Gitpages
 - Have a prototype!!! 
 - start reaching out to people for participating 
 - make a draft for data collection 
 - ERB 

## Entry 30/10/2023 - B&E ##

New legistlation for the US and GAI https://www.wired.com/story/joe-bidens-executive-order-ai-us-government-chatgpt/ 

''...the Defense Production Act, a law that can compel businesses to take actions in the interest of national security, to require the makers of large AI models to report key information to the government, including when they are training a new model and what cybersecurity protections they have.''

''Another part of the order requires companies that acquire, develop, or possess large-scale computing clusters, essential to training the most powerful AI systems, to report their activity to the federal government. This rule is intended to help the government understand which entities, including those from nations competing with the US, have strong AI capabilities.''

It's intersting to see how the US is almost weaponizing GAI, as well as forcing direct opportunity for the government. Since I'm only making GPT calls, in the best scenario, I don't think this applies to me persé. However, if I wanted to actually make this, the source of the model should be explainable, key information should be collected and presented, and explain what cyber security is set in place. 


## Entry 27/10/2023 - C&A ##

![image](https://github.com/FemkeKocken/FMP/assets/50365794/036320e1-a97c-4060-8b08-e2be5c07d2de)
SO I'm trying to make a dark version of a webpage, but honestly I might have to put it to rest for now and pick it back up next week. I'm a little exhausted. 

Did also find this image: 
blue-ish computer face design kinda vibe. Which would be a cool thing I could potentially explore. Why the added middle man of a assistent, if you could also speak to your laptop directly?
I could take this idea into potential meetings as well. 

![image](https://github.com/FemkeKocken/FMP/assets/50365794/378f9386-f0e2-4685-b37c-aecdb552a579)



## Entry 27/10/2023 - Business ##
In the meanwhile I'm just now reading about this new article that has passed UK law surrounding digital safety. It's pretty controversial. Moest importantly messages can now get scanned to filter out illegal content
''Some of the more nuanced principles around the harms caused by legal but harmful content have been watered down, and added in is a highly divisive requirement for messaging platforms to scan users’ messages for illegal material, such as child sexual abuse material, which tech companies and privacy campaigners say is an unwarranted attack on encryption.''

also: 
-age requirements 
-reporting concerns
-any treats of suicide, murder, cyberbullying and deepfake porn must be removed from the platform. 

https://www.wired.com/story/the-uks-controversial-online-safety-act-is-now-law/

## Entry 26/10/2023 - Realization ##
Okay I think I've found a good tool to use, Locofy. This will help me to turn a Figma file into React.js in such a way that I would almost believe I could then host it on Github (this is going be great for my portfolio, but I can't do it for the prototype as you can't publish a GPT key online..)
This could be promising. I could try and make an aesthically better version and see if I could upload it to Git pages to test the waters? 


## Entry 26/10/2023 - Aesthetics ##

Finished the first figma desktop sketch. FINALLY. 

![image](https://github.com/FemkeKocken/FMP/assets/50365794/c00a51c4-f09d-4721-a831-6e68e244ce24)

I think this looks a little bit too cloowny.. I do still like the unstable lay-overs. But I definitly need to go with dark mode.  
Maybe I should explore glitchy textures a bit as well. 

## Entry 25/10/2023 - Aesthetics ## 
Hallelujah! I inally finsih that damn "quick'' easy sketch I was going to do lol. 

![image](https://github.com/FemkeKocken/FMP/assets/50365794/f8be9e21-7203-428a-9690-09345bc607f0)

I still kind of like the unstable identity glitch idea. Or trying to communicate the idea of instability and fluidity through the design of the app.

I also started on the Figma for  the webpage but honestly, I'm just too tired man. I'll continue tomorrow.

## Entry 25/10/2023 - realization ##

So now I am looking into React, and the idea is to make a Figma prototype, and see if that can be turned into React with a tool. I suppose that from there I can ask for help in letting it make API calls to GPT. 

The planning for now is out of the window. 
I really need some support from Rilla and/or Minha... 

I'll also have to look more into learning to understand React and find a tool to go from Figma to React. 

As far for the tool, my first Youtube tutorial attempt is actually making it seem like it's not too much of a hassle. 
SO far I've learned that there's Vite or kind of a slower way to go from Figma to React JS 
and theres the Rendition tool that will create component directly. 
I'll have to watch these full tutorials sometime soon to see if that would work. 

## Entry 24/10/2023 - maybe go back to drawing board ##

Just spoke to Rachel, she mentioned that maybe the whole assistent thing is not going to work out...  
However some other things I could try in the meanwhil is to WoZ somethings, or influence apps. I can also look up React Native. 
I definitly need a chat with Rilla to iron some things down because I need to make soething real soon. 

one thing I do know: is that I want to stimulate discussion around human-like interactions with computers. 

I'm just not sure what I want exactly. 

Rachel also mentioned mturk, red door and snow crash. 

## Entry 24/10/2023 -realization ## 

So Shahrom, Max and Rilla helped me out a lot by explaining the inner workings of it all and what I can best do in order to make this work: 

So I got very stuck on the realization part, as I didn't know how to code and there would be inbetween, 2^5=32 and 5^5=3125 variation based on the slider idea, all with a certain personality tied to it. Essentially way too much. 

What I want is to design a front end with a method of calling GPT over the web. Therefore, mobile design should be left to rest for nowand I should focus on making a working webpage first. Since ky skills in HTML and CSS are basic and incredibly dusty and my skill in JS basically non-existent. I will probably have to use libraries to bear the main load of the prototyping. I was recommended: React, React Native, Angular, Svelte, NextJS, and Nest JS. The can function as a foundation for the webpage and will save me time and effort. As for the realization this will mean that I should look into React Native and look for tools that would turn a Figma file into code/React Native. 

As for the concept having to set different personalities will probably make it harder to code. While having only one set personality would be hard to arguea s to go for which personality exactly. I'm kinda of stuck on this..

## etnry 21/10/2023 - Research process ##

Okay so Max adviced to maybe do one type personality, like Rilla said and base that on the average personality of the people I ask. THat way I would only  have to mae 1 prototype/chatbot. WHich would narrow things down quite a lot. I should also ask Shahrom and Rachel on their opinions. I could ask Miriam for a relieable questionaire. 

From there I would also need to nail down the following: 
 - What type of participant
 - how many participants
 - how to approach the diary study
 - what questions should I ask 

Perhaps this list should be better in the journal? not  sure 

## Entry 20/10/2023 - concept ##

SO far I've received help from Max and Rilla. 
THey also advised me not to continue to think about actually realizing this because it is simply put, too much dam work. 
However, I could continue with a single setting. 

### Question: whih setting/personality should that be and why? ###

alright I'll get bck to you tomorrow. As I also want to finish a drawing so I have atleast something to point when talking about this concept, you know.

## Entry 20/10/2023 - concept ##

I thought it could be interesting to keep a log of the development of my prototype here (I guess that was part of whole GaR project, I'm just a bigger idiot than people think) 
Anways, okay so I don't have too much time right now so I'll copy paste the beginning of the concept here and I guess I'll add more to it later. 

right now I am mostly interested in building a virtual assistant/chatbot that would utilize the big 5 (OCEAN) personality traits. The assistant would be to create a direct interaction and relationship between user and LLM. The research question would be something along the lines of: How do users respond to the introduction of human-like personalities within assistants?  
 
In an ideal world where I could do everything want, I would love to make would be a site/platform/app. For now, let’s say a website, that would have a chat window as well as 5 unmarked sliders corresponding to these 5 traits and give those off to users. I would ideally let users test on the 5 personality traits, and base the starting values for the site on these results (so a personality similar to their own). I would then follow the users over the span of a couple days, and let them play around with the settings, give them some daily tasks, probably doing a diary study. I would close it off with an interview on the user experience and what settings they preferred in what situations and if I could comment on current trend and UX design in general. 
 
However, this is not an ideal world, and I am honestly not sure how to go about this and realize this. I am going to look more into this myself as well, and see how far I could get, but there is also very limited time given the TUe calendar. I could see if I could use Github pages and maybe even generate parts of the code? 
Any and all advise would help a lot. 
